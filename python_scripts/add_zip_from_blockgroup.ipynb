{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739e2a3f-c2ca-48b0-bbfa-dfaa89474788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading relationship file: https://www2.census.gov/geo/docs/maps-data/data/rel/2020/zcta_tract_rel_20.xlsx\n",
      "  -> Failed to use https://www2.census.gov/geo/docs/maps-data/data/rel/2020/zcta_tract_rel_20.xlsx: 404 Client Error: Not Found for url: https://www2.census.gov/geo/docs/maps-data/data/rel/2020/zcta_tract_rel_20.xlsx\n",
      "Downloading relationship file: https://www2.census.gov/geo/docs/maps-data/data/rel/zcta_tract_rel_10.txt\n",
      "✅ Wrote: Howard_demographics_block_2022-2023_with_zip.csv\n",
      "ZIP coverage: 276/332 rows mapped.\n",
      "Note: Some tracts can map to multiple ZCTAs; we chose the dominant one by weight if available.\n"
     ]
    }
   ],
   "source": [
    "# add_zip_from_blockgroup_autofetch.py\n",
    "# ---------------------------------------------------\n",
    "# Runs in the SAME FOLDER as your CSV.\n",
    "# Input : Howard_demographics_block_2022-2023.csv (needs 'county_name')\n",
    "# Output: Howard_demographics_block_2022-2023_with_zip.csv\n",
    "#\n",
    "# What it does if no local crosswalk is present:\n",
    "#   1) Downloads Census tract↔ZCTA relationship file (2020 preferred; 2010 fallback).\n",
    "#   2) Filters to Maryland (STATE=24), builds 11-digit tract GEOID.\n",
    "#   3) Picks dominant ZCTA per tract (based on largest available weight column).\n",
    "#   4) Joins your Block Group rows (via tract) to add a ZIP column.\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Filenames (current folder) ----------\n",
    "IN_CSV  = \"Howard_demographics_block_2022-2023.csv\"\n",
    "OUT_CSV = \"Howard_demographics_block_2022-2023_with_zip.csv\"\n",
    "\n",
    "# Optional local crosswalks (if you’ve already got them)\n",
    "LOCAL_BG = [\"bg_to_zcta_md.csv\", \"bg_to_zcta_us.csv\"]\n",
    "LOCAL_TR = [\"tract_to_zcta_md.csv\", \"tract_to_zcta_us.csv\"]\n",
    "\n",
    "# Known Census relationship file URLs (2020 preferred, 2010 fallback)\n",
    "REMOTE_RELATIONSHIP_SOURCES = [\n",
    "    # 2020 relationship (Excel). This is the current preferred file.\n",
    "    \"https://www2.census.gov/geo/docs/maps-data/data/rel/2020/zcta_tract_rel_20.xlsx\",\n",
    "    # 2010 relationship (TXT/CSV-like)\n",
    "    \"https://www2.census.gov/geo/docs/maps-data/data/rel/zcta_tract_rel_10.txt\",\n",
    "]\n",
    "\n",
    "# FIPS constants\n",
    "STATE_FIPS_MD = \"24\"   # Maryland\n",
    "\n",
    "# -------- Helpers --------\n",
    "TRACT_RE = re.compile(\n",
    "    r\"Block\\s*Group\\s*(?P<bg>\\d+)\\s*;\\s*Census\\s*Tract\\s*(?P<tract>[0-9.]+)\\s*;\\s*(?P<county>[^;]+)\\s*;\\s*(?P<state>.+)$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def tract_to_6d(tract_str: str) -> str:\n",
    "    \"\"\"Convert '6011.03' → '601103', '6012' → '601200'\"\"\"\n",
    "    if not isinstance(tract_str, str):\n",
    "        return None\n",
    "    ts = tract_str.strip()\n",
    "    if \".\" in ts:\n",
    "        left, right = ts.split(\".\", 1)\n",
    "        left = re.sub(r\"\\D\", \"\", left)\n",
    "        right = re.sub(r\"\\D\", \"\", right)\n",
    "        return f\"{left.zfill(4)}{right.zfill(2)}\"\n",
    "    else:\n",
    "        left = re.sub(r\"\\D\", \"\", ts)\n",
    "        return f\"{left.zfill(4)}00\"\n",
    "\n",
    "def parse_county_name(val: str):\n",
    "    \"\"\"Parse your county_name string into bg, tract6, county, state.\"\"\"\n",
    "    if not isinstance(val, str):\n",
    "        return {\"bg\": None, \"tract6\": None, \"county\": None, \"state\": None}\n",
    "    m = TRACT_RE.search(val.strip())\n",
    "    if not m:\n",
    "        return {\"bg\": None, \"tract6\": None, \"county\": None, \"state\": None}\n",
    "    return {\n",
    "        \"bg\": m.group(\"bg\").strip(),\n",
    "        \"tract6\": tract_to_6d(m.group(\"tract\")),\n",
    "        \"county\": m.group(\"county\").strip(),\n",
    "        \"state\": m.group(\"state\").strip(),\n",
    "    }\n",
    "\n",
    "def find_first_existing(names):\n",
    "    for nm in names:\n",
    "        if os.path.exists(nm):\n",
    "            return nm\n",
    "    return None\n",
    "\n",
    "def choose_weight_col(df):\n",
    "    for c in [\"POPPT\", \"AREAPT\", \"AREALANDPT\", \"RES_RATIO\", \"BUS_RATIO\", \"pop_share\", \"aland_share\", \"area_share\", \"weight\", \"share\"]:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def normalize_zcta_col(df):\n",
    "    # Try multiple common ZCTA column names → \"zcta5\"\n",
    "    for c in [\"ZCTA5\", \"ZCTA5CE10\", \"ZCTA5CE20\", \"ZCTA\", \"zcta5\", \"zcta\"]:\n",
    "        if c in df.columns:\n",
    "            df = df.rename(columns={c: \"zcta5\"})\n",
    "            break\n",
    "    if \"zcta5\" in df.columns:\n",
    "        df[\"zcta5\"] = df[\"zcta5\"].astype(str).str.zfill(5)\n",
    "    return df\n",
    "\n",
    "def add_tract_geoid11(df):\n",
    "    \"\"\"Create 11-digit tract GEOID column 'tract_geoid11' from parts, if needed.\"\"\"\n",
    "    # If already present under some common names, normalize to 'tract_geoid11'\n",
    "    for c in [\"GEOID\", \"GEOID10\", \"GEOID20\", \"TRACT_GEOID\", \"tract_geoid11\"]:\n",
    "        if c in df.columns:\n",
    "            df = df.rename(columns={c: \"tract_geoid11\"})\n",
    "            df[\"tract_geoid11\"] = df[\"tract_geoid11\"].astype(str).str.zfill(11)\n",
    "            return df\n",
    "\n",
    "    # Else try building from parts\n",
    "    state_cand  = None\n",
    "    county_cand = None\n",
    "    tract_cand  = None\n",
    "    for c in [\"STATE\", \"STATEFP\", \"STATEFP10\", \"STATEFP20\"]:\n",
    "        if c in df.columns: state_cand = c; break\n",
    "    for c in [\"COUNTY\", \"COUNTYFP\", \"COUNTYFP10\", \"COUNTYFP20\"]:\n",
    "        if c in df.columns: county_cand = c; break\n",
    "    for c in [\"TRACT\", \"TRACTCE\", \"TRACTCE10\", \"TRACTCE20\"]:\n",
    "        if c in df.columns: tract_cand = c; break\n",
    "\n",
    "    if state_cand and county_cand and tract_cand:\n",
    "        df[\"tract_geoid11\"] = (\n",
    "            df[state_cand].astype(str).str.zfill(2) +\n",
    "            df[county_cand].astype(str).str.zfill(3) +\n",
    "            df[tract_cand].astype(str).str.zfill(6)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Could not identify columns to build 'tract_geoid11' from the relationship file.\")\n",
    "    return df\n",
    "\n",
    "def load_relationship_crosswalk():\n",
    "    \"\"\"\n",
    "    Try:\n",
    "      1) local block-group crosswalk,\n",
    "      2) local tract crosswalk,\n",
    "      3) download 2020/2010 tract↔ZCTA from Census.\n",
    "    Return a DataFrame with columns: tract_geoid11, zcta5, and a weight col (optional).\n",
    "    \"\"\"\n",
    "    # 1) Local BG crosswalk (rare): we can collapse to tract if needed, but we’ll prefer tract level uniformly\n",
    "    bg_local = find_first_existing(LOCAL_BG)\n",
    "    if bg_local:\n",
    "        xw = pd.read_csv(bg_local, dtype=str, encoding=\"utf-8-sig\")\n",
    "        xw = normalize_zcta_col(xw)\n",
    "        # If it’s truly BG-level with 'bg_geoid', reduce to tract by slicing first 11 chars\n",
    "        if \"bg_geoid\" in xw.columns and \"tract_geoid11\" not in xw.columns:\n",
    "            xw[\"tract_geoid11\"] = xw[\"bg_geoid\"].astype(str).str.slice(0, 11)\n",
    "        if \"tract_geoid11\" not in xw.columns:\n",
    "            raise ValueError(f\"{bg_local} is missing tract info; expected 'bg_geoid' or 'tract_geoid11'.\")\n",
    "        return xw\n",
    "\n",
    "    # 2) Local tract crosswalk\n",
    "    tr_local = find_first_existing(LOCAL_TR)\n",
    "    if tr_local:\n",
    "        tx = pd.read_csv(tr_local, dtype=str, encoding=\"utf-8-sig\")\n",
    "        tx = normalize_zcta_col(tx)\n",
    "        if \"tract_geoid11\" not in tx.columns:\n",
    "            # Try to infer from a generic 'tract' column\n",
    "            if \"tract\" in tx.columns:\n",
    "                tx[\"tract_geoid11\"] = tx[\"tract\"].astype(str).str.zfill(11)\n",
    "            else:\n",
    "                raise ValueError(f\"{tr_local} must have 'tract_geoid11' or 'tract' column.\")\n",
    "        return tx\n",
    "\n",
    "    # 3) Download from Census (2020 preferred, 2010 fallback)\n",
    "    import requests\n",
    "    last_err = None\n",
    "    for url in REMOTE_RELATIONSHIP_SOURCES:\n",
    "        try:\n",
    "            print(f\"Downloading relationship file: {url}\")\n",
    "            resp = requests.get(url, timeout=60)\n",
    "            resp.raise_for_status()\n",
    "\n",
    "            if url.endswith(\".xlsx\"):\n",
    "                rel = pd.read_excel(io.BytesIO(resp.content), dtype=str)\n",
    "            else:\n",
    "                # 2010 TXT is pipe or comma-delimited; let pandas sniff\n",
    "                rel = pd.read_csv(io.StringIO(resp.text), dtype=str)\n",
    "\n",
    "            # Normalize columns\n",
    "            rel = normalize_zcta_col(rel)\n",
    "            rel = add_tract_geoid11(rel)\n",
    "\n",
    "            # Filter to Maryland (STATE 24) if a state column exists; otherwise filter by tract prefix\n",
    "            state_col = None\n",
    "            for c in [\"STATE\", \"STATEFP\", \"STATEFP10\", \"STATEFP20\"]:\n",
    "                if c in rel.columns: state_col = c; break\n",
    "\n",
    "            if state_col:\n",
    "                rel_md = rel[rel[state_col].astype(str).str.zfill(2) == STATE_FIPS_MD].copy()\n",
    "            else:\n",
    "                # Filter by tract_geoid11 prefix\n",
    "                rel_md = rel[rel[\"tract_geoid11\"].astype(str).str.startswith(STATE_FIPS_MD)].copy()\n",
    "\n",
    "            # Keep essential columns\n",
    "            cols_keep = [\"tract_geoid11\", \"zcta5\"]\n",
    "            # Add a weight if present\n",
    "            wcol = choose_weight_col(rel_md)\n",
    "            if wcol and wcol not in cols_keep:\n",
    "                cols_keep.append(wcol)\n",
    "            rel_md = rel_md[cols_keep].dropna(subset=[\"tract_geoid11\", \"zcta5\"])\n",
    "\n",
    "            # If multiple ZCTAs per tract, keep the dominant by weight (or first if none)\n",
    "            if wcol:\n",
    "                rel_md = (rel_md.sort_values(wcol, ascending=False)\n",
    "                                  .drop_duplicates(subset=[\"tract_geoid11\"], keep=\"first\"))\n",
    "            else:\n",
    "                rel_md = rel_md.drop_duplicates(subset=[\"tract_geoid11\"], keep=\"first\")\n",
    "\n",
    "            return rel_md.reset_index(drop=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            print(f\"  -> Failed to use {url}: {e}\")\n",
    "\n",
    "    raise RuntimeError(f\"Could not obtain a tract↔ZCTA relationship file. Last error: {last_err}\")\n",
    "\n",
    "# -------- Main --------\n",
    "def main():\n",
    "    if not os.path.exists(IN_CSV):\n",
    "        sys.exit(f\"Input file not found: {IN_CSV}\")\n",
    "\n",
    "    df = pd.read_csv(IN_CSV, dtype=str, encoding=\"utf-8-sig\")\n",
    "    if \"county_name\" not in df.columns:\n",
    "        sys.exit(\"The input CSV must contain a 'county_name' column.\")\n",
    "\n",
    "    parsed = df[\"county_name\"].apply(parse_county_name).apply(pd.Series)\n",
    "    df = pd.concat([df, parsed], axis=1)\n",
    "\n",
    "    # Keep Maryland/Howard rows (your file already is, but it's safe)\n",
    "    md_mask = df[\"state\"].str.contains(\"Maryland\", case=False, na=False)\n",
    "    df = df.loc[md_mask].copy()\n",
    "\n",
    "    # Build tract GEOID (11 digits): 24 + 027 + tract6  (Howard county = 027)\n",
    "    df[\"tract_geoid11\"] = \"24\" + \"027\" + df[\"tract6\"].fillna(\"\")\n",
    "\n",
    "    # Load or fetch relationship crosswalk (tract→ZCTA)\n",
    "    rel = load_relationship_crosswalk()\n",
    "\n",
    "    # Merge and write\n",
    "    out = df.merge(rel[[\"tract_geoid11\", \"zcta5\"]], on=\"tract_geoid11\", how=\"left\")\n",
    "    out = out.rename(columns={\"zcta5\": \"zip\"})\n",
    "    out.to_csv(OUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    total = len(out)\n",
    "    mapped = out[\"zip\"].notna().sum()\n",
    "    print(f\"✅ Wrote: {OUT_CSV}\")\n",
    "    print(f\"ZIP coverage: {mapped}/{total} rows mapped.\")\n",
    "    if mapped < total:\n",
    "        print(\"Note: Some tracts can map to multiple ZCTAs; we chose the dominant one by weight if available.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a932b4b-6cf7-424e-a197-e97cd6f5f2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
