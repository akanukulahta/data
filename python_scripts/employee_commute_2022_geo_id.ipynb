{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d2b5d7-93b8-4db2-aebc-c73de7a500be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://lehd.ces.census.gov/data/lodes/LODES8/md/od/md_od_main_JT00_2022.csv.gz\n",
      "LODES rows: 1,979,851\n",
      "Unique blocks in OD: 67,546\n",
      "Loading TIGER Blocks (2020, statewide)…\n",
      "Downloading: https://www2.census.gov/geo/tiger/TIGER2020/TABBLOCK20/tl_2020_24_tabblock20.zip\n",
      "Blocks subset for OD: 67,546\n",
      "Loading ZCTA5 (2020, generalized)…\n",
      "Downloading: https://www2.census.gov/geo/tiger/GENZ2020/shp/cb_2020_us_zcta520_500k.zip\n",
      "Computing block centroids for spatial join…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanuk\\AppData\\Local\\Temp\\ipykernel_17604\\2488725898.py:151: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  blocks_sub[\"centroid\"] = blocks_sub.geometry.centroid\n",
      "C:\\Users\\kanuk\\AppData\\Local\\Temp\\ipykernel_17604\\2488725898.py:152: FutureWarning: The `drop` keyword argument is deprecated and in future the only supported behaviour will match drop=False. To silence this warning and adopt the future behaviour, stop providing `drop` as a keyword to `set_geometry`. To replicate the `drop=True` behaviour you should update your code to\n",
      "`geo_col_name = gdf.active_geometry_name; gdf.set_geometry(new_geo_col).drop(columns=geo_col_name).rename_geometry(geo_col_name)`.\n",
      "  blocks_pts = blocks_sub.set_geometry(\"centroid\", drop=False)[[\"block_geoid\", \"centroid\"]].rename(columns={\"centroid\": \"geometry\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial join block → ZCTA…\n",
      "✅ Wrote: out_md_lodes\\employment_commute_md_2022_JT00.csv\n"
     ]
    }
   ],
   "source": [
    "# employment_commute_build.py\n",
    "# ------------------------------------------------------------\n",
    "# Creates employment_commute.csv from LEHD LODES OD + TIGER/CB shapefiles\n",
    "# Schema:\n",
    "#   home_geo_id (Census Block GEOID, 15 chars)\n",
    "#   work_geo_id (Census Block GEOID, 15 chars)\n",
    "#   commuter_count (S000)\n",
    "#   net_commute_flow (inflow - outflow for the HOME block)\n",
    "#   data_year\n",
    "#   source\n",
    "# Optional extras (can be dropped later): home_zcta, work_zcta\n",
    "#\n",
    "# Requirements:\n",
    "#   pip install pandas geopandas requests shapely pyproj\n",
    "#   (geopandas requires system deps: GEOS/PROJ; on Windows use conda-forge)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import io\n",
    "import gzip\n",
    "import zipfile\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import tempfile\n",
    "\n",
    "# ---------- Parameters ----------\n",
    "STATE_ABBR = \"md\"         # 2-letter lower-case for LODES (e.g., \"md\")\n",
    "STATE_FIPS = \"24\"         # Maryland FIPS\n",
    "YEAR = 2022               # LODES OD year (e.g., 2022)\n",
    "JOBTYPE = \"JT00\"          # LODES job type (JT00: all jobs; JT01: primary; JT02: secondary)\n",
    "CRS_EPSG = 4326           # Work in WGS84 for simplicity\n",
    "\n",
    "OUT_DIR = \"out_md_lodes\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# LODES v8 OD URL (update if needed)\n",
    "LODES_OD_URL = f\"https://lehd.ces.census.gov/data/lodes/LODES8/{STATE_ABBR}/od/{STATE_ABBR}_od_main_{JOBTYPE}_{YEAR}.csv.gz\"\n",
    "\n",
    "# TIGER/Line 2020 Blocks (statewide)\n",
    "# (Statewide blocks shapefile for 2020)\n",
    "BLOCKS_URL = f\"https://www2.census.gov/geo/tiger/TIGER2020/TABBLOCK20/tl_2020_{STATE_FIPS}_tabblock20.zip\"\n",
    "\n",
    "# Cartographic Boundary (generalized, lightweight) ZCTA5 2020 (national)\n",
    "# Much smaller than full TIGER ZCTA; we’ll clip by state bounding box after load\n",
    "ZCTA_URL = \"https://www2.census.gov/geo/tiger/GENZ2020/shp/cb_2020_us_zcta520_500k.zip\"\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def download_to_bytes(url: str) -> bytes:\n",
    "    print(f\"Downloading: {url}\")\n",
    "    r = requests.get(url, stream=True, timeout=120)\n",
    "    r.raise_for_status()\n",
    "    return r.content\n",
    "\n",
    "def read_lodes_od(url: str) -> pd.DataFrame:\n",
    "    raw = download_to_bytes(url)\n",
    "    with gzip.GzipFile(fileobj=io.BytesIO(raw), mode='rb') as gz:\n",
    "        df = pd.read_csv(gz, dtype={\"h_geocode\": str, \"w_geocode\": str})\n",
    "    # Keep only needed columns: S000 = total jobs in OD pair\n",
    "    if \"S000\" not in df.columns:\n",
    "        raise ValueError(\"LODES file missing S000 column (total jobs).\")\n",
    "    df = df[[\"h_geocode\", \"w_geocode\", \"S000\"]].rename(columns={\"S000\": \"commuter_count\"})\n",
    "    # Strip whitespace just in case\n",
    "    df[\"h_geocode\"] = df[\"h_geocode\"].str.strip()\n",
    "    df[\"w_geocode\"] = df[\"w_geocode\"].str.strip()\n",
    "    # Filter non-positive\n",
    "    df = df[df[\"commuter_count\"] > 0].copy()\n",
    "    return df\n",
    "\n",
    "def read_zipped_shapefile(url: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Download a zipped shapefile, extract to a temp directory, and read the .shp.\n",
    "    This avoids pyogrio/fiona issues with 'zip://<BytesIO>' on some systems.\n",
    "    \"\"\"\n",
    "    print(f\"Downloading: {url}\")\n",
    "    import requests\n",
    "    r = requests.get(url, stream=True, timeout=180)\n",
    "    r.raise_for_status()\n",
    "    content = r.content\n",
    "\n",
    "    # Extract to a temp directory\n",
    "    tmpdir = tempfile.mkdtemp(prefix=\"shp_\")\n",
    "    with zipfile.ZipFile(io.BytesIO(content)) as zf:\n",
    "        zf.extractall(tmpdir)\n",
    "\n",
    "    # Find the .shp file inside the zip\n",
    "    shp_candidates = []\n",
    "    for root, _, files in os.walk(tmpdir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(\".shp\"):\n",
    "                shp_candidates.append(os.path.join(root, f))\n",
    "    if not shp_candidates:\n",
    "        raise RuntimeError(\"No .shp file found inside the ZIP.\")\n",
    "    shp_path = shp_candidates[0]  # take the first layer by default\n",
    "\n",
    "    # Read with GeoPandas (pyogrio engine if available)\n",
    "    return gpd.read_file(shp_path)\n",
    "\n",
    "# ---------- Pipeline ----------\n",
    "# 1) Read LODES OD\n",
    "od = read_lodes_od(LODES_OD_URL)\n",
    "print(f\"LODES rows: {len(od):,}\")\n",
    "\n",
    "# 2) Compute net flow per HOME block: (inflow - outflow)\n",
    "# Inflow by block = sum of commuter_count where block appears as w_geocode\n",
    "inflow = od.groupby(\"w_geocode\")[\"commuter_count\"].sum().rename(\"inflow\")\n",
    "# Outflow by block = sum of commuter_count where block appears as h_geocode\n",
    "outflow = od.groupby(\"h_geocode\")[\"commuter_count\"].sum().rename(\"outflow\")\n",
    "\n",
    "# Build a table of all blocks appearing in either role\n",
    "all_blocks = pd.Index(sorted(set(od[\"h_geocode\"]) | set(od[\"w_geocode\"])), name=\"block_geoid\")\n",
    "net_tbl = pd.DataFrame(index=all_blocks).join(inflow, how=\"left\", on=\"block_geoid\").join(outflow, how=\"left\", on=\"block_geoid\")\n",
    "net_tbl = net_tbl.fillna(0)\n",
    "net_tbl[\"net_commute_flow\"] = net_tbl[\"inflow\"] - net_tbl[\"outflow\"]\n",
    "print(f\"Unique blocks in OD: {len(net_tbl):,}\")\n",
    "\n",
    "# Map net flow back to OD rows as the HOME block’s net (you can also attach WORK block’s net if desired)\n",
    "od = od.join(net_tbl[\"net_commute_flow\"], how=\"left\", on=\"h_geocode\")\n",
    "\n",
    "# 3) Optional: Attach ZCTAs via spatial join\n",
    "#    This is helpful for ZIP-level reporting, but not part of the required schema.\n",
    "print(\"Loading TIGER Blocks (2020, statewide)…\")\n",
    "blocks = read_zipped_shapefile(BLOCKS_URL)\n",
    "# Standardize cols\n",
    "# GEOID20 is the full 15-digit Census Block GEOID for 2020\n",
    "if \"GEOID20\" not in blocks.columns:\n",
    "    # Some releases use GEOID or GEOID10; try to discover automatically\n",
    "    candidates = [c for c in [\"GEOID20\", \"GEOID10\", \"GEOID\"] if c in blocks.columns]\n",
    "    if not candidates:\n",
    "        raise ValueError(\"Blocks shapefile missing GEOID column.\")\n",
    "    geoid_col = candidates[0]\n",
    "else:\n",
    "    geoid_col = \"GEOID20\"\n",
    "\n",
    "blocks = blocks[[geoid_col, \"geometry\"]].rename(columns={geoid_col: \"block_geoid\"})\n",
    "blocks = blocks.to_crs(epsg=CRS_EPSG)\n",
    "\n",
    "# Keep only blocks appearing in OD to lighten the spatial join\n",
    "blocks_sub = blocks[blocks[\"block_geoid\"].isin(net_tbl.index)].copy()\n",
    "print(f\"Blocks subset for OD: {len(blocks_sub):,}\")\n",
    "\n",
    "print(\"Loading ZCTA5 (2020, generalized)…\")\n",
    "zcta = read_zipped_shapefile(ZCTA_URL)\n",
    "zcta = zcta.to_crs(epsg=CRS_EPSG)\n",
    "# Keep only fields we need\n",
    "zcta = zcta[[\"ZCTA5CE20\", \"geometry\"]].rename(columns={\"ZCTA5CE20\": \"zcta5\"})\n",
    "\n",
    "# Spatial join: block centroid within ZCTA polygon\n",
    "print(\"Computing block centroids for spatial join…\")\n",
    "blocks_sub[\"centroid\"] = blocks_sub.geometry.centroid\n",
    "blocks_pts = blocks_sub.set_geometry(\"centroid\", drop=False)[[\"block_geoid\", \"centroid\"]].rename(columns={\"centroid\": \"geometry\"})\n",
    "blocks_pts = gpd.GeoDataFrame(blocks_pts, geometry=\"geometry\", crs=f\"EPSG:{CRS_EPSG}\")\n",
    "\n",
    "print(\"Spatial join block → ZCTA…\")\n",
    "blk2zcta = gpd.sjoin(blocks_pts, zcta, how=\"left\", predicate=\"within\")[[\"block_geoid\", \"zcta5\"]]\n",
    "\n",
    "# Build lookups for home/work blocks\n",
    "home_lookup = blk2zcta.set_index(\"block_geoid\")[\"zcta5\"].to_dict()\n",
    "work_lookup = home_lookup  # same dict; mapping from any block to its ZCTA\n",
    "\n",
    "od[\"home_zcta\"] = od[\"h_geocode\"].map(home_lookup)\n",
    "od[\"work_zcta\"] = od[\"w_geocode\"].map(work_lookup)\n",
    "\n",
    "# 4) Finalize schema and export\n",
    "employment_commute = pd.DataFrame({\n",
    "    \"home_geo_id\": od[\"h_geocode\"],\n",
    "    \"work_geo_id\": od[\"w_geocode\"],\n",
    "    \"commuter_count\": od[\"commuter_count\"].astype(\"int64\"),\n",
    "    # Net for the HOME block (inflow - outflow); negative means net exporter of commuters\n",
    "    \"net_commute_flow\": od[\"net_commute_flow\"].astype(\"int64\"),\n",
    "    \"data_year\": YEAR,\n",
    "    \"source\": f\"LEHD LODES8 OD {JOBTYPE}\",\n",
    "    # Optional extras (drop if you want the minimal schema)\n",
    "    \"home_zcta\": od[\"home_zcta\"],\n",
    "    \"work_zcta\": od[\"work_zcta\"],\n",
    "})\n",
    "\n",
    "# Minimal schema only (uncomment to drop ZCTAs)\n",
    "# employment_commute = employment_commute[[\n",
    "#     \"home_geo_id\", \"work_geo_id\", \"commuter_count\", \"net_commute_flow\", \"data_year\", \"source\"\n",
    "# ]]\n",
    "\n",
    "out_csv = os.path.join(OUT_DIR, f\"employment_commute_{STATE_ABBR}_{YEAR}_{JOBTYPE}.csv\")\n",
    "employment_commute.to_csv(out_csv, index=False)\n",
    "print(f\"✅ Wrote: {out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98560318-47d4-4733-b94d-1920c59241b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
