{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4878bd0f-e11c-4726-bd91-7eb863e5002a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  No crosswalk CSV found in this folder.\n",
      "Place one of the following files here and rerun the script:\n",
      "  - bg_to_zcta_md.csv  (preferred)\n",
      "  - bg_to_zcta_us.csv\n",
      "  - tract_to_zcta_md.csv  (fallback)\n",
      "  - tract_to_zcta_us.csv  (fallback)\n",
      "Expected columns are documented at the top of this script.\n",
      "✅ Wrote: Howard_demographics_block_2022-2023_with_zip.csv\n",
      "ZIP coverage: 0/332 rows mapped.\n",
      "Note: Some rows have no ZIP—check crosswalk coverage or parsing.\n"
     ]
    }
   ],
   "source": [
    "# add_zip_from_blockgroup.py\n",
    "# ---------------------------------------------\n",
    "# Run from the SAME FOLDER as your CSV file.\n",
    "# Input : Howard_demographics_block_2022-2023.csv (must have a 'county_name' column)\n",
    "# Output: Howard_demographics_block_2022-2023_with_zip.csv\n",
    "#\n",
    "# How ZIPs are added:\n",
    "# 1) Parse \"county_name\" like:\n",
    "#    \"Block Group 1; Census Tract 6011.03; Howard County; Maryland\"\n",
    "# 2) Build Block Group GEOID = state FIPS (24) + county FIPS (027) + tract(6) + blockGroup(1)\n",
    "# 3) Join to a local crosswalk CSV to map Block Group → ZCTA (ZIP).\n",
    "#\n",
    "# Place ONE of these crosswalk files in the SAME FOLDER (any one works):\n",
    "#  - bg_to_zcta_md.csv            (columns: bg_geoid,zcta5[,pop_share|aland_share])\n",
    "#  - bg_to_zcta_us.csv            (nationwide; columns: bg_geoid,zcta5[,share])\n",
    "#  - tract_to_zcta_md.csv         (columns: tract_geoid11,zcta5[,share])  <-- fallback (tract-level)\n",
    "#  - tract_to_zcta_us.csv         (nationwide; columns: tract_geoid11,zcta5[,share])\n",
    "#\n",
    "# If multiple ZCTAs exist per geography, the row with the largest weight\n",
    "# (pop_share/aland_share/area_share/weight/share) is chosen.\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------ CONFIG ------------------\n",
    "IN_CSV  = \"Howard_demographics_block_2022-2023.csv\"\n",
    "OUT_CSV = \"Howard_demographics_block_2022-2023_with_zip.csv\"\n",
    "\n",
    "# Preferred file names to search (in this folder)\n",
    "BG_XWALK_CANDIDATES = [\n",
    "    \"bg_to_zcta_md.csv\",     # Maryland-only block-group crosswalk\n",
    "    \"bg_to_zcta_us.csv\",     # US block-group crosswalk\n",
    "]\n",
    "TRACT_XWALK_CANDIDATES = [\n",
    "    \"tract_to_zcta_md.csv\",  # Maryland-only tract crosswalk\n",
    "    \"tract_to_zcta_us.csv\",  # US tract crosswalk\n",
    "]\n",
    "\n",
    "WEIGHT_COLS = [\"pop_share\", \"aland_share\", \"area_share\", \"weight\", \"share\"]\n",
    "\n",
    "# FIPS (Howard County, Maryland)\n",
    "STATE_FIPS_MD = \"24\"\n",
    "COUNTY_FIPS_HOWARD = \"027\"\n",
    "\n",
    "# ------------------ HELPERS ------------------\n",
    "TRACT_RE = re.compile(\n",
    "    r\"Block\\s*Group\\s*(?P<bg>\\d+)\\s*;\\s*Census\\s*Tract\\s*(?P<tract>[0-9.]+)\\s*;\\s*(?P<county>[^;]+)\\s*;\\s*(?P<state>.+)$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def tract_to_6d(tract_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert human-formatted tract like '6011.03' or '6012.3' or '6012'\n",
    "    to 6-digit Census tract code (e.g., '601103', '601230', '601200').\n",
    "    \"\"\"\n",
    "    if not isinstance(tract_str, str):\n",
    "        return None\n",
    "    ts = tract_str.strip()\n",
    "    if \".\" in ts:\n",
    "        left, right = ts.split(\".\", 1)\n",
    "        left = re.sub(r\"\\D\", \"\", left)\n",
    "        right = re.sub(r\"\\D\", \"\", right)\n",
    "        return f\"{left.zfill(4)}{right.zfill(2)}\"\n",
    "    else:\n",
    "        left = re.sub(r\"\\D\", \"\", ts)\n",
    "        return f\"{left.zfill(4)}00\"\n",
    "\n",
    "def parse_county_name(val: str):\n",
    "    \"\"\"\n",
    "    Parse 'county_name' like:\n",
    "    'Block Group 1; Census Tract 6011.03; Howard County; Maryland'\n",
    "    \"\"\"\n",
    "    if not isinstance(val, str):\n",
    "        return {\"bg\": None, \"tract6\": None, \"county\": None, \"state\": None}\n",
    "    m = TRACT_RE.search(val.strip())\n",
    "    if not m:\n",
    "        return {\"bg\": None, \"tract6\": None, \"county\": None, \"state\": None}\n",
    "    bg = m.group(\"bg\").strip()\n",
    "    tract6 = tract_to_6d(m.group(\"tract\"))\n",
    "    county = m.group(\"county\").strip()\n",
    "    state = m.group(\"state\").strip()\n",
    "    return {\"bg\": bg, \"tract6\": tract6, \"county\": county, \"state\": state}\n",
    "\n",
    "def build_bg_geoid(tract6: str, bg: str) -> str:\n",
    "    \"\"\"\n",
    "    BG GEOID (12) = 24 (MD) + 027 (Howard) + tract(6) + blockgroup(1)\n",
    "    \"\"\"\n",
    "    if pd.isna(tract6) or pd.isna(bg):\n",
    "        return None\n",
    "    return f\"{STATE_FIPS_MD}{COUNTY_FIPS_HOWARD}{tract6}{int(bg)}\"\n",
    "\n",
    "def choose_dominant(df: pd.DataFrame, key_col: str, cols_keep):\n",
    "    \"\"\"\n",
    "    If multiple rows per key exist and a weight column is present, keep the\n",
    "    highest-weight row per key. Otherwise, drop duplicates keeping first.\n",
    "    \"\"\"\n",
    "    weight_col = None\n",
    "    for c in WEIGHT_COLS:\n",
    "        if c in df.columns:\n",
    "            weight_col = c\n",
    "            break\n",
    "    if weight_col:\n",
    "        return (df.sort_values(weight_col, ascending=False)\n",
    "                  .drop_duplicates(subset=[key_col], keep=\"first\")[cols_keep])\n",
    "    else:\n",
    "        return df[cols_keep].drop_duplicates()\n",
    "\n",
    "def find_first_existing(candidates):\n",
    "    for fname in candidates:\n",
    "        if os.path.exists(fname):\n",
    "            return fname\n",
    "    return None\n",
    "\n",
    "# ------------------ MAIN ------------------\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(IN_CSV):\n",
    "        sys.exit(f\"Input file not found: {IN_CSV}\")\n",
    "\n",
    "    # Load input\n",
    "    df = pd.read_csv(IN_CSV, dtype=str, encoding=\"utf-8-sig\")\n",
    "    if \"county_name\" not in df.columns:\n",
    "        sys.exit(\"The input CSV must contain a 'county_name' column.\")\n",
    "\n",
    "    # Parse the descriptive field\n",
    "    parsed = df[\"county_name\"].apply(parse_county_name).apply(pd.Series)\n",
    "    df = pd.concat([df, parsed], axis=1)\n",
    "\n",
    "    # Optional filter (should already be Howard, MD)\n",
    "    mask_hoco = (df[\"county\"].str.contains(\"Howard\", case=False, na=False)) & \\\n",
    "                (df[\"state\"].str.contains(\"Maryland\", case=False, na=False))\n",
    "    df = df.loc[mask_hoco].copy()\n",
    "\n",
    "    # GEOIDs\n",
    "    df[\"tract6\"]   = df[\"tract6\"]\n",
    "    df[\"bg_geoid\"] = df.apply(lambda r: build_bg_geoid(r[\"tract6\"], r[\"bg\"]), axis=1)\n",
    "    df[\"tract_geoid11\"] = df[\"bg_geoid\"].str.slice(0, 11)  # state2 + county3 + tract6\n",
    "\n",
    "    # Try BLOCK-GROUP crosswalk first\n",
    "    zip_col = None\n",
    "    bg_xwalk_path = find_first_existing(BG_XWALK_CANDIDATES)\n",
    "    tract_xwalk_path = find_first_existing(TRACT_XWALK_CANDIDATES)\n",
    "\n",
    "    if bg_xwalk_path:\n",
    "        xw = pd.read_csv(bg_xwalk_path, dtype={\"bg_geoid\": str, \"zcta5\": str}, encoding=\"utf-8-sig\")\n",
    "        xw_dom = choose_dominant(xw, \"bg_geoid\", [\"bg_geoid\", \"zcta5\"])\n",
    "        merged = df.merge(xw_dom, on=\"bg_geoid\", how=\"left\")\n",
    "        merged.rename(columns={\"zcta5\": \"zip\"}, inplace=True)\n",
    "        zip_col = \"zip\"\n",
    "        out = merged\n",
    "\n",
    "    elif tract_xwalk_path:\n",
    "        # Fallback: map via TRACT→ZCTA, then broadcast to BGs within the tract\n",
    "        tx = pd.read_csv(tract_xwalk_path, dtype=str, encoding=\"utf-8-sig\")\n",
    "        # Normalize expected columns\n",
    "        # Accept either 'tract_geoid11' or 'tract' column with 11-digit GEOID\n",
    "        if \"tract_geoid11\" not in tx.columns:\n",
    "            # Try to infer from a 'tract' column\n",
    "            if \"tract\" in tx.columns:\n",
    "                tx[\"tract_geoid11\"] = tx[\"tract\"].astype(str).str.zfill(11)\n",
    "            else:\n",
    "                sys.exit(f\"Tract crosswalk '{tract_xwalk_path}' must have 'tract_geoid11' (or 'tract').\")\n",
    "\n",
    "        if \"zcta5\" not in tx.columns:\n",
    "            sys.exit(f\"Tract crosswalk '{tract_xwalk_path}' must have 'zcta5' column.\")\n",
    "\n",
    "        tx_dom = choose_dominant(tx, \"tract_geoid11\", [\"tract_geoid11\", \"zcta5\"])\n",
    "        merged = df.merge(tx_dom, on=\"tract_geoid11\", how=\"left\")\n",
    "        merged.rename(columns={\"zcta5\": \"zip\"}, inplace=True)\n",
    "        zip_col = \"zip\"\n",
    "        out = merged\n",
    "\n",
    "    else:\n",
    "        # No crosswalk found; write file without ZIP and message\n",
    "        out = df.copy()\n",
    "        out[\"zip\"] = pd.NA\n",
    "        print(\n",
    "            \"⚠️  No crosswalk CSV found in this folder.\\n\"\n",
    "            \"Place one of the following files here and rerun the script:\\n\"\n",
    "            \"  - bg_to_zcta_md.csv  (preferred)\\n\"\n",
    "            \"  - bg_to_zcta_us.csv\\n\"\n",
    "            \"  - tract_to_zcta_md.csv  (fallback)\\n\"\n",
    "            \"  - tract_to_zcta_us.csv  (fallback)\\n\"\n",
    "            \"Expected columns are documented at the top of this script.\"\n",
    "        )\n",
    "\n",
    "    # Save\n",
    "    out.to_csv(OUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ Wrote: {OUT_CSV}\")\n",
    "\n",
    "    # Simple sanity print\n",
    "    if \"zip\" in out.columns:\n",
    "        missing = int(out[\"zip\"].isna().sum())\n",
    "        total   = len(out)\n",
    "        print(f\"ZIP coverage: {total - missing}/{total} rows mapped.\")\n",
    "        if missing:\n",
    "            print(\"Note: Some rows have no ZIP—check crosswalk coverage or parsing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc261e10-139b-46f2-a6d0-e929e881e92f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
